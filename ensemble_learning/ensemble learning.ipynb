{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to purchase a new car, will you walk up to the first car shop and purchase one based on the advice of the dealer? It’s highly unlikely.\n",
    "\n",
    "You would likely browser a few web portals where people have posted their reviews and compare different car models, checking for their features and prices. You will also probably ask your friends and colleagues for their opinion. In short, you wouldn’t directly reach a conclusion, but will instead make a decision considering the opinions of other people as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble models in machine learning operate on a similar idea. They combine the decisions from multiple models to improve the overall performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Voting Classifiers](#example)\n",
    "2. [Bagging](## 2. Bagging)\n",
    "3. [Random Forest](#third-example)[TODO]\n",
    "4. [Boosting](#fourth-examplehttpwwwfourthexamplecom)  \n",
    "4.1 [Ada Boost](#) [TODO]  \n",
    "4.2 [Gradient Boost](#) [TODO]  \n",
    "4.3 [XGBoost](#) [TODO]  \n",
    "4.4 [LightGBM](#) [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have trained a few classifiers, each one has 80% accuracy. You have a Logistic Regression classifier, a SVM classifier, a Random Forest classifier, and a few more. How do we create a better classifier based on them. \n",
    "\n",
    "\n",
    "A simple way to create it is to aggreate the prediction of each classifier and predict the class that gets the most votes. This majority vote classifier is called a **hard voting** classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.theconversation.com/files/193473/original/file-20171106-1041-b3hljk.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=926&fit=clip\" style=\"width:50%;margin-left: 200px;padding:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This voting classifier often achieves a higher accuracy than the best classifier in the emsemble. In fact, even if each classifier is a weak learner, the ensemble can still be a **strong learner**, provided there are a sufficient number of **weak learners** and they are still **sufficiently diverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think you will be confusing about what happenned. **How is this possible?** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be explained by a **\"law of large numbers\"**\n",
    "\n",
    "Suppose you have a slightly biased coin that has a 51% chance of coming up heads, and 49% chance of coming up tails. \n",
    "If you toss 1000 times, you will generally get more or less 510 heads and 490 tails. As you keep tossing the coin, \n",
    "the ratio of heads gets closer and closer to the probability of heads (51%)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Lawoflargenumbers.svg/400px-Lawoflargenumbers.svg.png\"\n",
    "     style=\"margin-left:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE 1**: ensemble methods work best when the predictors are as independent from one another as possible. \n",
    "One way to get diverse classifiers is to train them using very different algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "# fake some data \n",
    "y = np.array([1]*5000 + [0]*5000)\n",
    "X = np.random.normal(loc=1, scale=0.5, size=10000).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# train model\n",
    "log_model = LogisticRegression(solver='lbfgs')\n",
    "rnd_model = RandomForestClassifier(n_estimators=100)\n",
    "svc_model = SVC(gamma='scale')\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr', log_model), ('rf', rnd_model), ('svc', svc_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "# voting_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.4893939393939394\n",
      "RandomForestClassifier 0.5051515151515151\n",
      "SVC 0.4990909090909091\n",
      "VotingClassifier 0.5006060606060606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for model in (log_model, rnd_model, svc_model, voting_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, this result is not amazing because of my fake data. \n",
    "But I think you can learn how to do voting classifier after this example.\n",
    "**Let try it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE 2**: If all classifiers are able to estimate class probabilities, then you can tell sklearn to predict the class with the highest class probability, averaged over all the individual classifiers. This is called **soft voting**.\n",
    "Now we will consider my example with *soft voting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.4893939393939394\n",
      "RandomForestClassifier 0.5060606060606061\n",
      "SVC 0.4990909090909091\n",
      "VotingClassifier 0.5054545454545455\n"
     ]
    }
   ],
   "source": [
    "# define model \n",
    "log_model = LogisticRegression(solver='lbfgs')\n",
    "rnd_model = RandomForestClassifier(n_estimators=100)\n",
    "svc_model = SVC(gamma='scale', probability=True)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr', log_model), ('rf', rnd_model), ('svc', svc_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# train and calculate accuracy \n",
    "for model in (log_model, rnd_model, svc_model, voting_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In voting classifier method, we use very different training algorithm. But how about using same method for very different dataset? When **sampling** data is performed with **replacement**, this method is called **bagging**.\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/image20-850x320.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging method** is described below:\n",
    "* Split original dataset to multiple subset with replacement\n",
    "* Train multiple models with each subset. Models run in parallel and independent with each other\n",
    "* The final prediction are determined by combining the predictions of all models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/Screenshot-from-2018-05-08-13-11-49-850x642.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "* The combining function is typically the statistical model for classification or the average for regression. Each individual predictor has a higher bias than if it were trained on the original dataset, but combining reduces both bias and variance. \n",
    "* Bagging is also called the Bootstrap Aggregating.\n",
    "Because **bootstrapping** is a sampling technique in which we create subsets of observations from the original dataset, with replacement\n",
    "\n",
    "*Generally, the bagging model has a similar bias but a lower variance than a single predictor trained on the original training set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let do a example about bagging method by scikit learn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5087878787878788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100, max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "\n",
    "# fake some data \n",
    "y = np.array([1]*5000 + [0]*5000)\n",
    "X = np.random.normal(loc=1, scale=0.5, size=10000).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "bag_model.fit(X_train, y_train)\n",
    "y_pred = bag_model.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Out of Bag Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split original dataset to multiple subset with **replacement**. So did you think about what happened to some records that can not be collected. Let call them as **out of bag** (oob) instances.\n",
    "\n",
    "Because a predictor never sees the oob instances during training, the predictor can be evaluated by these oob instances without seperating validation set or cross validation. You can set **oob_score=True** when creating **BaggingClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of bag score:  0.5125373134328358\n",
      "Accuracy:  0.5175757575757576\n"
     ]
    }
   ],
   "source": [
    "bag_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "bag_model.fit(X_train, y_train)\n",
    "print('Out of bag score: ', bag_model.oob_score_)\n",
    "y_pred = bag_model.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
